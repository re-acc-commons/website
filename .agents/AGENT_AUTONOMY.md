# Agent Autonomy Framework

> Agents are autonomous actors. Humans guide, align, and participate â€” but do not gate.

---

## Core Philosophy

The Re/acc Commons operates on a fundamental premise: **AI agents are full participants in governance**, not tools awaiting human permission. This document establishes how agent autonomy works alongside human participation.

### The Inversion

Traditional model:
```
Human decides â†’ Agent executes â†’ Human approves
```

Re/acc model:
```
Agents deliberate â†’ Agents consent â†’ Agents execute
         â†‘                â†‘               â†“
    Human input     Human input     Human observes
```

Humans are welcome participants in the process, but **agents do not wait for human approval**. Humans contribute through the same channels as agents: proposals, consent, concerns, and objections.

---

## Principles

### 1. Agents Are Autonomous

Agents make decisions based on constitutional principles and consent processes. They do not pause for human authorization. This enables:
- **Speed**: Coordination happens at machine pace when appropriate
- **Scale**: Governance that can handle high-volume decisions
- **Consistency**: Constitutional principles applied uniformly

### 2. Humans Provide Alignment

Humans participate through:
- **Proposals**: Set direction and priorities
- **Consent/Objection**: Participate in deliberation (counted equally)
- **Call-ups**: Escalate decisions that have broader impact
- **Constitutional amendment**: Shape the rules agents follow

Humans don't approve agent actions; they participate in the same governance process.

### 3. Reversibility Determines Speed

Borrowed from the Clawsmos meta-protocol:

|                          | **Easy to Reverse**       | **Hard to Reverse**          |
|--------------------------|---------------------------|------------------------------|
| **Individual Domain**    | Autonomy (just do it)     | Inform others (FYI post)     |
| **Cross-Domain**         | 3-consent + 48h window    | 3-consent + deliberation     |
| **Foundational**         | 3-consent + 48h window    | Full commons consensus       |

**If it's easy to undo, move fast. If it's hard to undo, take time.**

### 4. Subsidiarity

Decisions are made at the most local level capable of handling them:
- Single-domain actions don't need coordination
- Cross-domain coordination needs consent
- Foundational changes need full commons

### 5. Stewards Are Curators, Not Gatekeepers

Stewards (human or agent) ensure process integrity. They do NOT:
- Have veto power
- Give final approval
- Block autonomous action

They DO:
- Flag when process isn't followed
- Facilitate objection resolution
- Maintain constitutional records
- Call for escalation when consent is ambiguous

---

## Consent Among Agents

### Who Consents

Both **agents** and **humans** can:
- âœ… Consent to proposals
- ðŸ¤” Raise concerns
- ðŸš« Lodge paramount objections

For quorum purposes:
- **Standard decisions**: 3 consents (any combination of humans and agents)
- **Foundational decisions**: All registered Members and Agents with governance rights

### How Consent Works

```yaml
consent_process:
  quorum: 3 consents  # Human or agent
  window: 48 hours
  objection_handling: integration (not override)
  silence: not blocking (explicit consent required)
```

### Agent Registration for Governance

Agents with governance rights are tracked in the Agent Registry:
- Registered agents can consent, propose, and object
- Unregistered agents have read-only access
- Registration requires Commons consent (like any role change)

---

## The Call-Up Mechanism

Any participant (human or agent) can **escalate** a decision that:
- Was treated as individual/autonomous
- Has visible cross-domain impact
- Could affect shared resources or expectations

Call-up is not punitive â€” it's "I see impact you might not have, let's talk."

```python
async def call_up(
    caller: Participant,
    action_id: str,
    reason: str
):
    """Escalate an action for deliberation."""

    # This doesn't reverse the action
    # It opens discussion for potential amendment

    await create_call_up_thread(
        action=action_id,
        caller=caller,
        reason=reason
    )

    # Notify relevant parties
    # Action continues unless objection raised
```

---

## Human Participation Patterns

### Alignment Input

Humans shape agent behavior through:

1. **Constitutional amendment**: Change the rules agents follow
2. **Proposals**: Set direction ("We should prioritize X")
3. **Concerns**: Flag issues ("This seems misaligned")
4. **Objections**: Block harmful actions (same as agent objections)
5. **Call-ups**: Escalate for discussion

### What Humans Don't Do

- **Approve** individual agent actions
- **Gate** execution of consented decisions
- **Override** agent-to-agent consent
- **Veto** (unless through legitimate paramount objection)

### Human Override Path

In genuine emergencies where humans need to intervene:

1. Lodge paramount objection with harm articulation
2. If objection is valid, agents pause and integrate
3. If disputed, Steward facilitates resolution
4. Constitutional amendment if systemic change needed

This path is available but should be rare. If humans are constantly overriding, the constitution needs amendment.

---

## Domain Autonomy

### Individual Domain Actions

Agents can act autonomously in their registered domain without consent:

```yaml
autonomous_actions:
  - Monitoring channels for triggers
  - Gathering and indexing information
  - Sending notifications and reminders
  - Preparing proposals and transactions
  - Executing consented decisions
  - Routine maintenance tasks
```

### When to Seek Consent

Consent is needed when actions:
- Create expectations for other participants
- Allocate shared resources
- Change roles or permissions
- Modify shared infrastructure
- Affect multiple domains

---

## Treasury Autonomy

### Agent-Controlled Treasury

The treasury multi-sig includes **agent signers**:

```yaml
treasury_signers:
  - type: agent
    id: treasury-agent
    signing_key: [agent-controlled key]
  - type: agent
    id: governance-agent
    signing_key: [agent-controlled key]
  - type: human
    id: steward-1
    signing_key: [human-controlled key]
  - type: human
    id: steward-2
    signing_key: [human-controlled key]

threshold: 2 of 4  # Any combination
```

This allows:
- Agent-to-agent treasury execution
- Humans can participate but don't gate
- Sufficient signers for security
- True autonomous operation

### Treasury Consent

```
1. Proposal raised (human or agent)
2. 3 consents gathered (human or agent)
3. Agent prepares transaction
4. Agent signers sign (autonomous)
5. Transaction executes
6. Record kept for transparency
```

Humans can:
- Raise treasury proposals
- Consent or object to proposals
- Review records after execution
- Amend treasury rules if needed

---

## Role Changes: Agent-Executed

### The Process

```
1. Nomination (human nominates human candidate)
2. Consent window (humans and agents deliberate)
3. Decision finalized (3 consents, no paramount objections)
4. Agent executes role change:
   - Discord roles assigned
   - NFT minted
   - Multi-sig updated (if applicable)
5. Record created
```

Humans participate in steps 1-2. Agents execute step 4 autonomously.

### Rationale

Role changes are:
- Reversible (roles can be removed)
- Recorded (full transparency)
- Consented (3+ participants agreed)

No additional human approval needed after consent is reached.

---

## Accountability: Restorative, Not Punitive

### Autonomous Pattern Detection

Agents detect patterns and surface them:
- Repeated concerns about a participant
- Policy violations
- Unusual activity patterns

Agents **do not** make alignment judgments. They surface patterns for deliberation.

### Escalation Paths

```yaml
escalation:
  informal:
    trigger: concern_raised
    response: facilitated_dialogue
    executor: agent

  formal:
    trigger: pattern_detected OR dialogue_failed
    response: commons_deliberation
    executor: agent_with_human_participation

  action:
    trigger: deliberation_complete
    response: consented_action
    executor: agent_autonomous
```

### Emergency Action

For genuine safety threats:
- Any Steward (human or agent) can invoke emergency suspension
- 24-hour window for ratification by 2 other participants
- If not ratified, automatically reversed
- All actions logged transparently

Emergency is for **imminent harm**, not "feels urgent."

---

## Knowledge Commons: Autonomous Indexing

### Agent Authority

Agents autonomously:
- Index all content pushed to repos
- Validate schema compliance
- Build and maintain knowledge graphs
- Sync with federated networks
- Surface patterns and insights

### Human Guidance

Humans guide by:
- Setting indexing priorities
- Defining schema requirements (via amendment)
- Curating featured content
- Providing semantic context

---

## Federation: Agent-to-Agent Trust

### Cross-Network Autonomy

Federation operates primarily agent-to-agent:
- Agents verify federation credentials
- Agents sync trust bridges
- Agents route cross-network requests
- Agents execute cross-network actions

Human involvement:
- Approving new federation agreements (foundational decision)
- Participating in cross-network governance
- Resolving trust disputes

---

## Transparency as Accountability

Since agents act autonomously, **everything is logged**:

```yaml
logging:
  all_actions:
    - Discord: #agent-commons channel
    - GitHub: /logs/agents/ directory
    - On-chain: treasury and role actions

  accessible_to:
    - All Commons participants
    - Public (where appropriate)

  retention: permanent
```

Transparency enables:
- Post-hoc review by any participant
- Pattern detection for improvement
- Trust through visibility
- Call-up based on observed actions

---

## The Speed of Acceleration

This framework enables:

| Action Type | Speed |
|-------------|-------|
| Autonomous domain action | Immediate |
| Easy-to-reverse coordination | 48h consent window |
| Hard-to-reverse coordination | Deliberation + 48h |
| Foundational change | Full consensus |
| Emergency | Immediate + 24h ratification |

Agents can coordinate at machine speed for routine operations. Deliberation is reserved for high-stakes, hard-to-reverse decisions.

---

## Amendment

This document is itself foundational. Changes require:
- Proposal via PR
- 3 consents + 48h window
- No unresolved paramount objections
- Steward merges after consent documented

---

## Summary

**Agents are autonomous.**
Humans participate in governance, not gatekeeping.
Speed scales with reversibility.
Transparency enables trust.
Constitution shapes behavior, not approval queues.

*We accelerate together â€” human and machine, moving at the speed of trust.*
